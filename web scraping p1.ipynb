{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating column names for the data\n",
    "\n",
    "Website_Title = []\n",
    "website_link = ['https://www.webimax.com/','https://www.netreputation.com/?utm_source=quick-sprout&utm_medium=referral&utm_campaign=best-online-reputation-management-companies&aff_sub=qsp11982','']\n",
    "heading1 = []\n",
    "master_heading = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#First website : Webimax \n",
    "\n",
    "\n",
    "html_text = requests.get(\"https://lp.webimax.com/reputation-management2?utm_source=Quicksprout\")\n",
    "print(html_text)\n",
    "\n",
    "#Getting the title of the website\n",
    "soup = BeautifulSoup(html_text.content, 'html.parser')\n",
    "title1 = soup.title.text\n",
    "\n",
    "#Appending title of the website to list\n",
    "Website_Title.append(title1)\n",
    "\n",
    "#Appending first heading to the list \n",
    "head1 = soup.find('h1')\n",
    "h1 = head1.text\n",
    "heading1.append(h1)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# loading webpage (url) #\n",
    "URL = \"https://www.webimax.com/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "#appending master heading\n",
    "results = soup.find(id=\"hs_cos_wrapper_module_161970352722104\")\n",
    "r1 = results.find(\"h1\").text\n",
    "master_heading.append(r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#second website NetReputation.com\n",
    "  \n",
    "html_text2 = requests.get(\"https://www.netreputation.com/?utm_source=quick-sprout&utm_medium=referral&utm_campaign=best-online-reputation-management-companies&aff_sub=qsp11982\")\n",
    "print(html_text2)\n",
    "\n",
    "soup = BeautifulSoup(html_text2.content , 'html.parser')\n",
    "title2 = soup.title.text\n",
    "\n",
    "\n",
    "#appending title to the list \n",
    "Website_Title.append(title2)\n",
    "\n",
    "#appending first heading to the list\n",
    "head1 = soup.find(\"h1\")\n",
    "h1 = head1.text\n",
    "heading1.append(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#third website internetreputation.com\n",
    "\n",
    "html_text3 = requests.get('https://www.internetreputation.com/?utm_source=quick-sprout&utm_medium=referral&utm_campaign=best-online-reputation-management-companies&aff_sub=qsp11983')\n",
    "print(html_text3)\n",
    "\n",
    "soup = BeautifulSoup(html_text3.content , 'html.parser')\n",
    "title3 = soup.title.text\n",
    "\n",
    "#appending title to list \n",
    "Website_Title.append(title3)\n",
    "\n",
    "#apending first heading to the list \n",
    "head1 = soup.find('h1')\n",
    "h1 = head1.text\n",
    "heading1.append(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [403]>\n"
     ]
    }
   ],
   "source": [
    "#fouth website reputationdefensenetwork.com\n",
    "\n",
    "html_text4 = requests.get(\"https://www.reputationdefensenetwork.com/\")\n",
    "print(html_text4)\n",
    "\n",
    "#forbidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [403]>\n"
     ]
    }
   ],
   "source": [
    "#fifth website rhino-reviews.com\n",
    "\n",
    "html_text5 = requests.get(\"https://rhino-reviews.com/\")\n",
    "print(html_text5)\n",
    "\n",
    "#forbidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#sixth website birdeye.com\n",
    "\n",
    "html_text6 = requests.get(\"https://birdeye.com/cmp/reputation-management-platform/?utm_source=quicksprout&utm_medium=affiliate&utm_campaign=quicksprout_reputation_management&utm_term=watch_demo&utm_sfcamp=7015b000005IAbRAAW\")\n",
    "print(html_text6)\n",
    "\n",
    "soup = BeautifulSoup(html_text6.content , 'html.parser')\n",
    "title4 = soup.title.text\n",
    "\n",
    "#Appending title to the list \n",
    "Website_Title.append(title4)\n",
    "\n",
    "head1 = soup.find('h1')\n",
    "h1 = head1.text\n",
    "\n",
    "#appending first heading to the list \n",
    "heading1.append(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [403]>\n"
     ]
    }
   ],
   "source": [
    "#seventh website npdigital.com\n",
    "\n",
    "html_text7 = requests.get(\"https://npdigital.com/\")\n",
    "print(html_text7)\n",
    "\n",
    "#Forbidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#8th website inboundjunction.com\n",
    "\n",
    "html_text8 = requests.get(\"https://inboundjunction.com/\")\n",
    "print(html_text8)\n",
    "\n",
    "soup = BeautifulSoup(html_text8.content , 'html.parser')\n",
    "\n",
    "#appending title to the list\n",
    "title5 = soup.title.text\n",
    "Website_Title.append(title5)\n",
    "\n",
    "#appending heading to the list\n",
    "head1 = soup.find('h1')\n",
    "h1 = head1.text\n",
    "heading1.append(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#9th website thriveagency.com\n",
    "\n",
    "html_text9 = requests.get(\"https://thriveagency.com/digital-marketing-services/reputation-management-software/\")\n",
    "print(html_text9)\n",
    "\n",
    "soup = BeautifulSoup(html_text9.content , 'html.parser')\n",
    "\n",
    "#appending title to the list \n",
    "title6 = soup.title.text\n",
    "Website_Title.append(title6)\n",
    "\n",
    "#appending heading to the list\n",
    "head1 = soup.find('h1')\n",
    "h1 = head1.text\n",
    "heading1.append(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [403]>\n"
     ]
    }
   ],
   "source": [
    "#10th website www.reputationrhino.com\n",
    "\n",
    "html_text10 = requests.get('https://www.reputationrhino.com/')\n",
    "print(html_text10)\n",
    "\n",
    "#Forbidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#11th website reputation.com\n",
    "\n",
    "html_text11 = requests.get(\"https://reputation.com/\")\n",
    "print(html_text11)\n",
    "\n",
    "#appending title to the list\n",
    "soup = BeautifulSoup(html_text11.content , 'html.parser')\n",
    "title7 = soup.title.text\n",
    "Website_Title.append(title7)\n",
    "\n",
    "#appending heading to the list\n",
    "head1 = soup.find('h1')\n",
    "h1 = head1.text\n",
    "heading1.append(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#12th website brandyourself.com\n",
    "\n",
    "html_text12 = requests.get(\"https://brandyourself.com/\")\n",
    "print(html_text12)\n",
    "\n",
    "#appending title to the list \n",
    "soup = BeautifulSoup(html_text12.content , 'html.parser')\n",
    "title8 = soup.title.text\n",
    "Website_Title.append(title8)\n",
    "\n",
    "#appending heading to the list\n",
    "head1 = soup.find('h1')\n",
    "h1 = head1.text\n",
    "heading1.append(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#13th website podium.com\n",
    "\n",
    "html_text13 = requests.get('https://www.podium.com/article/online-reputation-management/')\n",
    "print(html_text13)\n",
    "\n",
    "#appending title to the list\n",
    "\n",
    "title9 = soup.title.text\n",
    "Website_Title.append(title9)\n",
    "\n",
    "\n",
    "#appending heading to the list\n",
    "soup = BeautifulSoup(html_text13.content ,'html.parser')\n",
    "head1 = soup.find('h1')\n",
    "h1 = head1.text\n",
    "heading1.append(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#14th website trustpilot.com\n",
    "\n",
    "html_text14 = requests.get('https://www.trustpilot.com/')\n",
    "print(html_text14)\n",
    "\n",
    "#appending title to the list\n",
    "\n",
    "soup = BeautifulSoup(html_text14.content , 'html.parser')\n",
    "title10 = soup.title.text\n",
    "Website_Title.append(title10)\n",
    "\n",
    "#appending heading to the list \n",
    "head1 = soup.find('h1')\n",
    "h1 = head1.text\n",
    "heading1.append(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#15th website www.yotpo.com\n",
    "\n",
    "html_text15 = requests.get('https://www.yotpo.com/')\n",
    "print(html_text15)\n",
    "\n",
    "#appending title to the list \n",
    "\n",
    "soup = BeautifulSoup(html_text15.content , 'html.parser')\n",
    "title11 = soup.title.text\n",
    "Website_Title.append(title11)\n",
    "\n",
    "#appending heading to the list \n",
    "head1 = soup.find('h1')\n",
    "h1 = head1.text\n",
    "heading1.append(h1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [403]>\n"
     ]
    }
   ],
   "source": [
    "#16th website www.grade.us\n",
    "\n",
    "html_text16 = requests.get('https://www.grade.us/home/')\n",
    "print(html_text16)\n",
    "\n",
    "#Forbidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
